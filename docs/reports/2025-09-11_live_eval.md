# Live ICL Evaluation — Sep 11, 2025

This report documents (1) the new ICL features we engineered, (2) live 30‑step results for Mixtral‑8x7B and DeepSeek‑R1 with evidence crediting, and (3) analysis, interpretation, and recommended run profiles. It also lists the most important project files to understand how the simulator works.

## 1) Features Added (Sep 2025)
- Controllers: LtM (PLAN→SOLVE) and ToT (width/depth, budget‑capped), seeded before SC.
- Uncertainty/entropy gating: escalates compute when confidence is low or vote entropy is high; can switch to ToT for escalated samples.
- Program‑of‑Thought (PoT): safe Python executor (`pyexec`) with strict AST allowlist and timeout; maps computed value → MCQ option.
- Grammar/JSON‑schema constraints: enforces MCQ answer shape when supported.
- Few‑shot KNN + MMR and optional cross‑encoder reranker: embedding backends `lexical|st|openai`, MMR diversification, optional rerank with `sentence-transformers` CrossEncoder.
- APE instruction header: prepend a tuned header to all student system prompts.
- Compression hook: LLMLingua‑lite heuristic compression for long few‑shot examples (engine hook ready for LLMLingua‑2).
- SC improvements: early‑stopping quorum and difficulty‑adaptive k.
- IDK preserved: abstention with calibrated score logging.

## 2) Live Results (30‑step, closed‑book, evidence crediting)

All runs used Fact‑Cards + required citations, grammar schema, self‑consistency + adaptive quorum, uncertainty gating, ToT controller (budgeted), and IDK. Metrics are computed on recovered logs when the original run terminated late; recovered files drop any partial last line.

### DeepSeek‑R1 (DeepInfra)
- File: `runs/live/deepseek_r1_maxdial_N30.jsonl.recovered` (N=30)
- credited_final = 0.33, raw_final = 0.40, attribution_gap = 0.07
- coverage_mean = 0.45, witness_final = 0.47
- mean_step_seconds ≈ 523.6, tokens/step ≈ 49.7k
- Top failure reasons: coverage_below_tau (16), witness_mismatch (16), no_option_quote_for_choice (13), tag_or_quote_filter (5)

### Mixtral‑8x7B (DeepInfra)
- File: `runs/live/mixtral_maxdial_N30.jsonl.recovered` (N=30)
- credited_final = 0.27, raw_final = 0.27, attribution_gap = 0.00
- coverage_mean = 0.42, witness_final = 0.37
- mean_step_seconds ≈ 86.4, tokens/step ≈ 24.2k
- Top failure reasons: no_option_quote_for_choice (21), witness_mismatch (19), coverage_below_tau (17), tag_or_quote_filter (1)

## 3) Earlier Baselines (for context)

### Mixtral (DeepInfra) — earlier profiles in `runs/exp/`
- `deepinfra_mistralai-Mixtral-8x7B-Instruct-v0.1_sc3_b8.jsonl` (N=33):
  - credited_final ≈ 0.39, raw_final ≈ 0.45, gap ≈ 0.06, coverage_mean ≈ 0.54, witness_final ≈ 0.45
  - mean_step_seconds ≈ 45.3, tokens/step ≈ 8.2k
- `mixtral_sc3_b6_lock.jsonl` (N=10):
  - credited_final = 0.40, raw_final = 0.40, gap = 0.00, coverage_mean ≈ 0.40, witness_final = 0.40
  - mean_step_seconds ≈ 65.0, tokens/step ≈ 9.3k

### DeepSeek‑R1 (DeepInfra) — earlier profiles in `runs/exp/`
- `deepinfra_deepseek-ai-DeepSeek-R1_sc3_b8.jsonl` (N=3):
  - credited_final = 0.33, raw_final = 0.33, gap = 0.00, coverage_mean ≈ 0.11, witness_final ≈ 0.33
  - mean_step_seconds ≈ 165.3, tokens/step ≈ 21.7k
- `r1_sc3_b6_lock.jsonl` (N=10):
  - credited_final = 0.20, raw_final = 0.20, gap = 0.00, coverage_mean ≈ 0.24, witness_final ≈ 0.30
  - mean_step_seconds ≈ 188.5, tokens/step ≈ 19.7k

## 4) Analysis & Interpretation
- Evidence is the bottleneck: The top misses across models are evidence‑linked: missing per‑option quotes (≤15 tokens), coverage below τ, and witness mismatches. Spending extra compute at answer time (ToT, uncertainty escalation, Best‑of) didn’t raise “credited” because LEARN (card extraction) wasn’t strengthened.
- Compute vs. credit: The “max‑dial” stack increased tokens and latency (especially for DeepSeek) without lifting credited beyond leaner profiles. Earlier Mixtral SC=3,budget=8 achieved higher credited (≈0.39) with much lower cost.
- What helps most: Stabilizing LEARN (Fact‑Cards extraction) with self‑consistency and preserving per‑option PRO cards; moderate SC; strict schema + citation rules.

## 5) Recommended Run Profiles

### Accuracy‑first (cheaper than max‑dial)
```
.venv/bin/python -m sim.cli \
  --student stateful-llm --provider deepinfra --model mistralai/Mixtral-8x7B-Instruct-v0.1 \
  --steps 30 --closed-book --context-position pre \
  --fact-cards --require-citations --cards-budget 10 --sc-extract 3 \
  --self-consistency 3 --adaptive-sc --sc-quorum 2 \
  --controller tot --tot-width 2 --tot-depth 2 --controller-budget 4 \
  --uncertainty-gate --conf-threshold 0.60 --entropy-threshold 0.85 --max-k-escalated 6 \
  --grammar schema --idk --target-confidence 0.60 \
  --use-tools --tools tfidf_retriever \
  --progress --log runs/live/mixtral_accfirst_N30.jsonl
```

### Cost‑first (feature‑rich but faster)
```
.venv/bin/python -m sim.cli \
  --student stateful-llm --provider deepinfra --model deepseek-ai/DeepSeek-R1 \
  --steps 30 --closed-book --context-position pre \
  --fact-cards --require-citations --cards-budget 10 --sc-extract 3 \
  --self-consistency 2 --adaptive-sc --sc-quorum 2 \
  --controller basic \
  --uncertainty-gate --conf-threshold 0.60 --entropy-threshold 0.85 --max-k-escalated 6 \
  --grammar schema --idk --target-confidence 0.60 \
  --use-tools --tools tfidf_retriever \
  --progress --log runs/live/deepseek_costfirst_N30.jsonl
```

### A/B/C sweep (isolate effects cleanly)
- A = Base (lean selection + strong LEARN): `--sc-extract 3`, controller=basic, no Best‑of, no ToT escalation
- B = A + ToT only: `--controller tot --tot-width 2 --tot-depth 2 --controller-budget 4`
- C = A + Best‑of only: controller=basic, `--best-of 6 --rerank confidence|evidence`

## 6) Operational Notes
- Recovery: If a run collapses, recover a clean file by truncating at the first invalid JSON line; analyze the `.recovered` file. Use `scripts.report_runs` and `scripts.analyze`.
- Temperature errors: Some hosted models accept only default temperatures via the Chat API. The recommended commands do not set explicit temperatures.
- Coverage τ: For quick sweeps, you can temporarily lower τ via `TUTOR_COVERAGE_TAU=0.35`; restore to 0.40 for final evaluations.

## 7) Most Important Files (Project Atlas)
- **Core Runtime**
  - `sim/orchestrator.py` — session loop; dials (SC, gating, controllers, grammar); LEARN/USE Fact‑Cards; evidence scoring; logging.
  - `sim/learner.py` — LLM + stateful LLM students; MCQ/SAQ/code/proof/table QA; PoT; controller hint/plan; APE header; JSON‑only prompts.
  - `sim/tasks.py` — task schemas and MCQ evaluator; SAQ/table/code task helpers.
  - `sim/evaluators.py` — safe code evaluator; proof/table QA graders.
  - `sim/validation.py` — quote validation; offset‑first and canonicalized substring (dash/space unification).
- **New Components**
  - `sim/controllers.py` — LtM/ToT controllers (budget‑capped) that seed votes before SC.
  - `sim/retrieval.py` — EmbeddingIndex (lexical/ST/OpenAI) + MMR; CrossEncoderReranker (optional).
  - `sim/tools.py` — tools registry; `SafePythonExecutor` for Program‑of‑Thought.
- **Model Wrappers**
  - `tutor/llm_openai.py` — fixed tutor wrapper; `OpenAIStudentLLM` for selectable OpenAI student models (e.g., gpt‑4.1).
  - `tutor/llm_deepinfra.py` — DeepInfra OpenAI‑compatible wrapper for hosted student models (DeepSeek, Mixtral).
- **Docs & Scripts**
  - `docs/icl_routing.md` — advanced ICL routing: controllers, gating, PoT, grammar, few‑shot KNN/MMR + reranker, APE, compression.
  - `docs/ICL_Simulator_Handbook.md` — simulator handbook + “What’s New (Sep 2025)”.
  - `docs/ICL_Agent_Next_Steps.md` — batching/benchmark guidance updated for adaptive SC and retrieval.
  - `scripts/report_runs.py`, `scripts/analyze.py` — summaries and deep analysis.
  - `scripts/active_prompt.py`, `scripts/ape_optimize.py` — labeling and header tuning helpers.

---

For questions or to add a small A/B/C batch harness script under `scripts/`, open an issue or ping the maintainers.

